//! Lifeguard Migration CLI Tool
//!
//! Command-line interface for managing database migrations in Lifeguard applications.
//! Supports both CLI execution and integration with CI/CD pipelines.

// Re-export from library
pub use lifeguard_migrate::sql_generator;

mod entity_loader;
mod entities;

use clap::{Parser, Subcommand};
use lifeguard::{connect, MayPostgresExecutor, LifeExecutor};
use lifeguard::migration::{Migrator, MigrationError};
use std::path::PathBuf;
use std::process;

#[derive(Parser)]
#[command(name = "lifeguard-migrate")]
#[command(about = "Migration management tool for Lifeguard ORM")]
#[command(version = "0.1.0")]
struct Cli {
    /// Database connection URL
    #[arg(long)]
    database_url: Option<String>,
    
    /// Migrations directory path
    #[arg(long, default_value = "migrations")]
    migrations_dir: PathBuf,
    
    /// Verbose output
    #[arg(short, long)]
    verbose: bool,
    
    /// Quiet output (errors only)
    #[arg(short, long)]
    quiet: bool,
    
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Show migration status (applied vs pending)
    Status,
    
    /// Apply pending migrations
    Up {
        /// Number of migrations to apply (default: all pending)
        #[arg(long)]
        steps: Option<usize>,
        
        /// Dry run - show what would be executed without running
        #[arg(long)]
        dry_run: bool,
    },
    
    /// Rollback migrations
    Down {
        /// Number of migrations to rollback (default: 1)
        #[arg(long, default_value = "1")]
        steps: usize,
        
        /// Dry run - show what would be rolled back
        #[arg(long)]
        dry_run: bool,
    },
    
    /// Validate checksums of applied migrations
    Validate,
    
    /// Generate a new migration file
    Generate {
        /// Migration name (e.g., "create_users_table")
        name: String,
    },
    
    /// Generate SQL migrations from entity definitions
    GenerateFromEntities {
        /// Output directory for generated SQL files (default: migrations/generated)
        #[arg(long, default_value = "migrations/generated")]
        output_dir: PathBuf,
        
        /// Entities directory (default: examples/entities)
        #[arg(long, default_value = "examples/entities")]
        entities_dir: PathBuf,
    },
    
    /// Show detailed migration information
    Info {
        /// Show information for a specific migration version
        #[arg(long)]
        version: Option<i64>,
    },
}

fn main() {
    let cli = Cli::parse();
    
    // Initialize logging
    if cli.quiet {
        env_logger::Builder::from_env(env_logger::Env::default().default_filter_or("error")).init();
    } else if cli.verbose {
        env_logger::Builder::from_env(env_logger::Env::default().default_filter_or("debug")).init();
    } else {
        env_logger::Builder::from_env(env_logger::Env::default().default_filter_or("info")).init();
    }
    
    // Check if command needs database connection
    let needs_db = !matches!(cli.command, Commands::GenerateFromEntities { .. } | Commands::Generate { .. });
    
    // Execute command (some commands don't need database connection)
    let result = match cli.command {
        Commands::GenerateFromEntities { output_dir, entities_dir } => {
            // This command doesn't need database connection
            match handle_generate_from_entities(&output_dir, &entities_dir) {
                Ok(()) => Ok(()),
                Err(e) => Err(MigrationError::InvalidFormat(e.to_string())),
            }
        },
        Commands::Generate { name } => handle_generate(&cli.migrations_dir, &name),
        _ => {
            // All other commands need database connection
            let database_url = cli.database_url
                .or_else(|| std::env::var("LIFEGUARD_DATABASE_URL").ok())
                .or_else(|| std::env::var("DATABASE_URL").ok())
                .ok_or_else(|| {
                    eprintln!("Error: Database URL not provided. Use --database-url or set LIFEGUARD_DATABASE_URL or DATABASE_URL environment variable.");
                    process::exit(1);
                })
                .unwrap();
            
            // Connect to database
            let client = match connect(&database_url) {
                Ok(client) => client,
                Err(e) => {
                    eprintln!("Error connecting to database: {}", e);
                    process::exit(1);
                }
            };
            
            let executor = MayPostgresExecutor::new(client);
            let migrator = Migrator::new(&cli.migrations_dir);
            
            match cli.command {
                Commands::Status => handle_status(&migrator, &executor),
                Commands::Up { steps, dry_run } => handle_up(&migrator, &executor, steps, dry_run),
                Commands::Down { steps, dry_run } => handle_down(&migrator, &executor, steps, dry_run),
                Commands::Validate => handle_validate(&migrator, &executor),
                Commands::Info { version } => handle_info(&migrator, &executor, version),
                _ => unreachable!(),
            }
        },
    };
    
    match result {
        Ok(()) => {
            if !cli.quiet {
                println!("‚úÖ Success");
            }
            process::exit(0);
        }
        Err(e) => {
            eprintln!("‚ùå Error: {}", e);
            process::exit(1);
        }
    }
}

fn handle_status(migrator: &Migrator, executor: &dyn LifeExecutor) -> Result<(), MigrationError> {
    let status = migrator.status(executor)?;
    
    println!("\nüìä Migration Status\n");
    
    if !status.applied.is_empty() {
        println!("‚úÖ Applied Migrations ({}):", status.applied_count);
        for record in &status.applied {
            let time_str = if let Some(ms) = record.execution_time_ms {
                format!("{}ms", ms)
            } else {
                "N/A".to_string()
            };
            println!("  ‚úì m{}_{} ({}, {})", 
                record.version, 
                record.name,
                record.applied_at.format("%Y-%m-%d %H:%M:%S"),
                time_str
            );
        }
    } else {
        println!("‚úÖ Applied Migrations: None");
    }
    
    println!();
    
    if !status.pending.is_empty() {
        println!("‚è≥ Pending Migrations ({}):", status.pending_count);
        for pending in &status.pending {
            println!("  ‚è≥ m{}_{} (pending)", pending.version, pending.name);
        }
    } else {
        println!("‚è≥ Pending Migrations: None");
    }
    
    println!("\nüìà Summary: {} applied, {} pending", status.applied_count, status.pending_count);
    
    Ok(())
}

fn handle_up(
    migrator: &Migrator,
    executor: &dyn LifeExecutor,
    steps: Option<usize>,
    dry_run: bool,
) -> Result<(), MigrationError> {
    if dry_run {
        let status = migrator.status(executor)?;
        if status.pending.is_empty() {
            println!("No pending migrations to apply");
            return Ok(());
        }
        
        let to_apply = steps.unwrap_or(status.pending.len());
        println!("Would apply {} migration(s):", to_apply);
        for (i, pending) in status.pending.iter().take(to_apply).enumerate() {
            println!("  {}. m{}_{}", i + 1, pending.version, pending.name);
        }
        return Ok(());
    }
    
    println!("Applying migrations...");
    let applied = migrator.up(executor, steps)?;
    
    if applied > 0 {
        println!("‚úÖ Successfully applied {} migration(s)", applied);
    } else {
        println!("‚úÖ No migrations to apply");
    }
    
    Ok(())
}

fn handle_down(
    migrator: &Migrator,
    executor: &dyn LifeExecutor,
    steps: usize,
    dry_run: bool,
) -> Result<(), MigrationError> {
    if dry_run {
        let status = migrator.status(executor)?;
        if status.applied.is_empty() {
            println!("No applied migrations to rollback");
            return Ok(());
        }
        
        let mut applied = status.applied;
        applied.sort_by_key(|m| std::cmp::Reverse(m.version));
        
        let to_rollback = steps.min(applied.len());
        println!("Would rollback {} migration(s):", to_rollback);
        for (i, record) in applied.iter().take(to_rollback).enumerate() {
            println!("  {}. m{}_{}", i + 1, record.version, record.name);
        }
        return Ok(());
    }
    
    println!("Rolling back migrations...");
    let rolled_back = migrator.down(executor, Some(steps))?;
    
    if rolled_back > 0 {
        println!("‚úÖ Successfully rolled back {} migration(s)", rolled_back);
    } else {
        println!("‚úÖ No migrations to rollback");
    }
    
    Ok(())
}

fn handle_validate(migrator: &Migrator, executor: &dyn LifeExecutor) -> Result<(), MigrationError> {
    println!("Validating checksums...");
    migrator.validate_checksums(executor)?;
    println!("‚úÖ All checksums valid");
    Ok(())
}

fn handle_generate(migrations_dir: &PathBuf, name: &str) -> Result<(), MigrationError> {
    use std::fs;
    use chrono::Utc;
    
    // Generate timestamp
    let now = Utc::now();
    let timestamp_str = now.format("%Y%m%d%H%M%S").to_string();
    let timestamp_num: i64 = timestamp_str.parse().unwrap_or(0);
    
    // Create migrations directory if it doesn't exist
    fs::create_dir_all(migrations_dir)
        .map_err(|e| MigrationError::FileNotFound(format!("Failed to create migrations directory: {}", e)))?;
    
    // Generate migration file name
    let filename = format!("m{}_{}.rs", timestamp_str, name);
    let filepath = migrations_dir.join(&filename);
    
    // CRITICAL: Check if file already exists to prevent overwriting
    // This prevents data loss if:
    // 1. User runs generate twice within the same second (same timestamp)
    // 2. A file with that name already exists
    // 3. Race conditions where file is created between check and write
    if filepath.exists() {
        return Err(MigrationError::FileAlreadyExists {
            path: filepath.display().to_string(),
        });
    }
    
    // Use atomic file creation to prevent race conditions
    // Open file with create_new flag (fails if file exists)
    use std::fs::OpenOptions;
    use std::io::Write;
    
    let mut file = OpenOptions::new()
        .write(true)
        .create_new(true)  // Atomic: fails if file exists
        .open(&filepath)
        .map_err(|e| {
            if e.kind() == std::io::ErrorKind::AlreadyExists {
                MigrationError::FileAlreadyExists {
                    path: filepath.display().to_string(),
                }
            } else {
                MigrationError::FileNotFound(format!("Failed to create migration file: {}", e))
            }
        })?;
    
    // Generate migration template
    let generated_time = now.format("%Y-%m-%d %H:%M:%S UTC").to_string();
    let template = format!(
        r#"//! Migration: {}
//! Version: {}
//! Generated: {}

use lifeguard::{{LifeError, migration::{{Migration, SchemaManager}}}};
use sea_query::{{Table, ColumnDef}};

pub struct Migration;

impl Migration for Migration {{
    fn name(&self) -> &str {{
        "{}"
    }}
    
    fn version(&self) -> i64 {{
        {}
    }}
    
    fn up(&self, manager: &SchemaManager) -> Result<(), LifeError> {{
        // TODO: Implement migration logic
        // Example:
        // let table = Table::create()
        //     .table("example")
        //     .col(ColumnDef::new("id").integer().not_null().primary_key())
        //     .to_owned();
        // manager.create_table(table)?;
        Ok(())
    }}
    
    fn down(&self, manager: &SchemaManager) -> Result<(), LifeError> {{
        // TODO: Implement rollback logic
        // Example:
        // let table = Table::drop().table("example").to_owned();
        // manager.drop_table(table)?;
        Ok(())
    }}
}}
"#,
        name, timestamp_str, generated_time, name, timestamp_num
    );
    
    // Write migration file (atomic operation - file already created with create_new)
    file.write_all(template.as_bytes())
        .map_err(|e| MigrationError::FileNotFound(format!("Failed to write migration file: {}", e)))?;
    
    file.sync_all()
        .map_err(|e| MigrationError::FileNotFound(format!("Failed to sync migration file: {}", e)))?;
    
    println!("‚úÖ Generated migration: {}", filepath.display());
    println!("   Edit the file to implement up() and down() methods");
    
    Ok(())
}

fn handle_generate_from_entities(
    output_dir: &PathBuf,
    entities_dir: &PathBuf,
) -> Result<(), Box<dyn std::error::Error>> {
    use entity_loader::load_entities;
    use std::fs;
    use chrono::Utc;
    
    println!("üîç Loading entities from: {}", entities_dir.display());
    
    // Load entities
    let entities = load_entities(entities_dir)?;
    
    if entities.is_empty() {
        println!("‚ö†Ô∏è  No entities found in {}", entities_dir.display());
        return Ok(());
    }
    
    println!("üìã Found {} entity(ies):", entities.len());
    for entity in &entities {
        println!("   - {} (table: {})", entity.name, entity.table_name);
    }
    
    // Create output directory if it doesn't exist
    if !output_dir.exists() {
        fs::create_dir_all(output_dir)?;
        println!("üìÅ Created output directory: {}", output_dir.display());
    }
    
    println!("\nüî® Generating SQL migrations...");
    
    // Generate SQL for each entity
    use lifeguard_migrate::sql_generator;
    use lifeguard::LifeModelTrait;
    
    let timestamp = Utc::now().format("%Y%m%d%H%M%S").to_string();
    
    // Group entities by service path for organized output
    use std::collections::HashMap;
    let mut entities_by_service: HashMap<Option<String>, Vec<&entity_loader::EntityInfo>> = HashMap::new();
    
    for entity_info in &entities {
        entities_by_service
            .entry(entity_info.service_path.clone())
            .or_insert_with(Vec::new)
            .push(entity_info);
    }
    
    // Generate SQL files per service
    for (service_path, service_entities) in entities_by_service {
        // Determine output file path based on service
        let service_output_dir = if let Some(ref service) = service_path {
            output_dir.join(service)
        } else {
            output_dir.clone()
        };
        
        // Create service-specific output directory
        if !service_output_dir.exists() {
            fs::create_dir_all(&service_output_dir)?;
        }
        
        let output_file = service_output_dir.join(format!("{}_generated_from_entities.sql", timestamp));
        
        let mut sql_content = String::new();
        sql_content.push_str(&format!("-- Migration: Generated from Lifeguard entities\n"));
        if let Some(ref service) = service_path {
            sql_content.push_str(&format!("-- Service: {}\n", service));
        }
        sql_content.push_str(&format!("-- Version: {}\n", timestamp));
        sql_content.push_str(&format!("-- Generated: {}\n\n", Utc::now().format("%Y-%m-%d %H:%M:%S UTC")));
        sql_content.push_str("-- This migration was automatically generated from entity definitions.\n");
        sql_content.push_str("-- DO NOT EDIT MANUALLY - regenerate from entities instead.\n\n");
        
        // Generate SQL for each entity in this service
        for entity_info in service_entities {
        let result = match entity_info.table_name.as_str() {
            "chart_of_accounts" => {
                use entities::chart_of_accounts::Entity;
                let table_def = Entity::table_definition();
                sql_generator::generate_create_table_sql::<Entity>(table_def)
            }
            "accounts" => {
                use entities::account::Entity;
                let table_def = Entity::table_definition();
                sql_generator::generate_create_table_sql::<Entity>(table_def)
            }
            "journal_entries" => {
                use entities::journal_entry::Entity;
                let table_def = Entity::table_definition();
                sql_generator::generate_create_table_sql::<Entity>(table_def)
            }
            "journal_entry_lines" => {
                use entities::journal_entry_line::Entity;
                let table_def = Entity::table_definition();
                sql_generator::generate_create_table_sql::<Entity>(table_def)
            }
            "account_balances" => {
                use entities::account_balance::Entity;
                let table_def = Entity::table_definition();
                sql_generator::generate_create_table_sql::<Entity>(table_def)
            }
            _ => {
                println!("   ‚ö†Ô∏è  Unknown entity table: {} (skipping)", entity_info.table_name);
                continue;
            }
        };
        
        match result {
            Ok(mut sql) => {
                // Special handling for account_balances: add generated column
                if entity_info.table_name == "account_balances" {
                    // Find the position to insert net_balance (after credit_balance, before currency_code)
                    // We need to find the line with credit_balance and insert after it
                    if let Some(pos) = sql.find("credit_balance NUMERIC(19, 4)") {
                        // Find the end of the credit_balance line (including the comma)
                        if let Some(line_end) = sql[pos..].find('\n') {
                            let line_start = pos;
                            let line_end_pos = pos + line_end;
                            let line = &sql[line_start..line_end_pos];
                            // Check if line already ends with a comma
                            let needs_comma = !line.trim_end().ends_with(',');
                            let insert_pos = line_end_pos;
                            let generated_col = if needs_comma {
                                ",\n    net_balance NUMERIC(19, 4) NOT NULL GENERATED ALWAYS AS (debit_balance - credit_balance) STORED,"
                            } else {
                                "\n    net_balance NUMERIC(19, 4) NOT NULL GENERATED ALWAYS AS (debit_balance - credit_balance) STORED,"
                            };
                            sql.insert_str(insert_pos, generated_col);
                        }
                    }
                }
                
                sql_content.push_str(&format!("-- Table: {}\n", entity_info.table_name));
                sql_content.push_str(&sql);
                sql_content.push_str("\n\n");
                println!("   ‚úÖ Generated SQL for {}", entity_info.table_name);
            }
            Err(e) => {
                eprintln!("   ‚ùå Failed to generate SQL for {}: {}", entity_info.table_name, e);
            }
        }
        }
        
        // Write the complete SQL file for this service
        fs::write(&output_file, sql_content)?;
        if let Some(ref service) = service_path {
            println!("‚úÖ Generated SQL migration for {}: {}", service, output_file.display());
        } else {
            println!("‚úÖ Generated SQL migration: {}", output_file.display());
        }
    }
    
    println!("‚úÖ Success");
    
    Ok(())
}

fn handle_info(migrator: &Migrator, executor: &dyn LifeExecutor, version: Option<i64>) -> Result<(), MigrationError> {
    let status = migrator.status(executor)?;
    
    if let Some(version) = version {
        // Show info for specific migration
        if let Some(record) = status.applied.iter().find(|r| r.version == version) {
            println!("\nüìã Migration Information\n");
            println!("Version: {}", record.version);
            println!("Name: {}", record.name);
            println!("Checksum: {}", record.checksum);
            println!("Applied At: {}", record.applied_at.format("%Y-%m-%d %H:%M:%S UTC"));
            if let Some(ms) = record.execution_time_ms {
                println!("Execution Time: {}ms", ms);
            }
            println!("Success: {}", record.success);
        } else if let Some(pending) = status.pending.iter().find(|p| p.version == version) {
            println!("\nüìã Migration Information (Pending)\n");
            println!("Version: {}", pending.version);
            println!("Name: {}", pending.name);
            println!("Checksum: {}", pending.checksum);
            println!("Status: Pending");
            println!("Path: {}", pending.path.display());
        } else {
            return Err(MigrationError::InvalidVersion(version));
        }
    } else {
        // Show summary info
        println!("\nüìã Migration System Information\n");
        println!("Total Migrations: {}", status.total);
        println!("Applied: {}", status.applied_count);
        println!("Pending: {}", status.pending_count);
        
        if let Some(latest) = status.latest_applied_version() {
            println!("Latest Applied Version: {}", latest);
        }
        
        if let Some(next) = status.next_pending_version() {
            println!("Next Pending Version: {}", next);
        }
    }
    
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use tempfile::TempDir;

    #[test]
    fn test_handle_generate_creates_file() {
        let temp_dir = TempDir::new().unwrap();
        let migrations_dir = temp_dir.path().to_path_buf();
        let name = "test_migration";
        
        let result = handle_generate(&migrations_dir, name);
        assert!(result.is_ok(), "Should successfully generate migration file");
        
        // Verify file was created
        let files: Vec<_> = fs::read_dir(&migrations_dir)
            .unwrap()
            .map(|e| e.unwrap().file_name())
            .collect();
        
        assert_eq!(files.len(), 1, "Should have exactly one migration file");
        assert!(files[0].to_string_lossy().starts_with("m"), "File should start with 'm'");
        assert!(files[0].to_string_lossy().contains(name), "File should contain migration name");
        assert!(files[0].to_string_lossy().ends_with(".rs"), "File should have .rs extension");
    }

    #[test]
    fn test_handle_generate_prevents_overwrite_existing_file() {
        let temp_dir = TempDir::new().unwrap();
        let migrations_dir = temp_dir.path().to_path_buf();
        let name = "duplicate_migration";
        
        // Generate first migration
        let result1 = handle_generate(&migrations_dir, name);
        assert!(result1.is_ok(), "First generation should succeed");
        
        // Get the filename that was created
        let files: Vec<_> = fs::read_dir(&migrations_dir)
            .unwrap()
            .map(|e| e.unwrap().file_name())
            .collect();
        assert_eq!(files.len(), 1);
        let first_filename = files[0].clone();
        
        // Read the original file content
        let original_path = migrations_dir.join(&first_filename);
        let original_content = fs::read_to_string(&original_path).unwrap();
        
        // Try to generate again with same name (will have different timestamp, but test the check)
        // Actually, to test the overwrite prevention, we need to simulate same timestamp
        // Let's manually create a file with the expected name pattern and try to generate
        
        // Wait a moment to ensure different timestamp, then try again
        std::thread::sleep(std::time::Duration::from_millis(1100));
        
        // Try to generate again - should succeed with different timestamp
        let result2 = handle_generate(&migrations_dir, name);
        assert!(result2.is_ok(), "Second generation with different timestamp should succeed");
        
        // Verify original file still exists and wasn't overwritten
        assert!(original_path.exists(), "Original file should still exist");
        let still_original_content = fs::read_to_string(&original_path).unwrap();
        assert_eq!(original_content, still_original_content, "Original file content should be unchanged");
        
        // Now test the actual overwrite scenario by manually creating a file
        // and then trying to generate with a forced same timestamp scenario
        // This is harder to test directly, so we'll test the file existence check
    }

    #[test]
    fn test_handle_generate_fails_when_file_exists() {
        let temp_dir = TempDir::new().unwrap();
        let migrations_dir = temp_dir.path().to_path_buf();
        let name = "existing_migration";
        
        // Manually create a file that would conflict
        use chrono::Utc;
        let now = Utc::now();
        let timestamp_str = now.format("%Y%m%d%H%M%S").to_string();
        let filename = format!("m{}_{}.rs", timestamp_str, name);
        let filepath = migrations_dir.join(&filename);
        
        // Create the file manually
        fs::create_dir_all(&migrations_dir).unwrap();
        fs::write(&filepath, "// Existing migration file\n").unwrap();
        
        // Now try to generate - should fail because file exists
        // Note: This will only fail if run within the same second
        // To make this test more reliable, we'll check the error handling
        let result = handle_generate(&migrations_dir, name);
        
        // The result depends on timing - if we're in the same second, it should fail
        // If we're in a different second, it will succeed with a different filename
        // So we'll verify the file existence check works by checking the created file
        if result.is_err() {
            // If it failed, verify it's the right error
            match result.unwrap_err() {
                MigrationError::FileAlreadyExists { .. } => {
                    // Expected - file exists check worked
                }
                e => panic!("Expected FileAlreadyExists error, got: {:?}", e),
            }
        } else {
            // If it succeeded, verify a new file was created (different timestamp)
            let files: Vec<_> = fs::read_dir(&migrations_dir)
                .unwrap()
                .map(|e| e.unwrap().file_name())
                .collect();
            // Should have 2 files now (original + new)
            assert!(files.len() >= 1, "Should have at least the original file");
        }
    }

    #[test]
    fn test_handle_generate_atomic_file_creation() {
        let temp_dir = TempDir::new().unwrap();
        let migrations_dir = temp_dir.path().to_path_buf();
        let name = "atomic_test";
        
        // Generate migration
        let result = handle_generate(&migrations_dir, name);
        assert!(result.is_ok(), "Should successfully generate migration file");
        
        // Verify file content is correct
        let files: Vec<_> = fs::read_dir(&migrations_dir)
            .unwrap()
            .map(|e| e.unwrap().file_name())
            .collect();
        
        assert_eq!(files.len(), 1);
        let filepath = migrations_dir.join(&files[0]);
        let content = fs::read_to_string(&filepath).unwrap();
        
        // Verify template content
        assert!(content.contains("Migration:"), "Should contain migration header");
        assert!(content.contains(name), "Should contain migration name");
        assert!(content.contains("fn up"), "Should contain up() method");
        assert!(content.contains("fn down"), "Should contain down() method");
        assert!(content.contains("impl Migration for Migration"), "Should contain Migration trait impl");
    }

    #[test]
    fn test_handle_generate_creates_directory() {
        let temp_dir = TempDir::new().unwrap();
        let migrations_dir = temp_dir.path().join("nonexistent_subdir");
        let name = "test_migration";
        
        // Directory doesn't exist yet
        assert!(!migrations_dir.exists());
        
        let result = handle_generate(&migrations_dir, name);
        assert!(result.is_ok(), "Should create directory and generate file");
        
        // Verify directory was created
        assert!(migrations_dir.exists(), "Directory should be created");
        assert!(migrations_dir.is_dir(), "Should be a directory");
    }
}
